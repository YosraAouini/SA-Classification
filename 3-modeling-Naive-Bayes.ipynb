{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark \n",
    "import warnings\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import HashingTF, CountVectorizer\n",
    "from pyspark.ml.feature import IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Naive bayes Model\") \\\n",
    "   .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "######## Import Labeled Data (Corpus) \n",
    "df= spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").option(\"inferSchema\", \"true\").option(\"header\",\"true\").csv(\"Output\\data_corpus.csv\")\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceData = df.selectExpr(\"Text as sentence \", \"cast(label as int) as label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceData=sentenceData.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceData = sentenceData.withColumn('sentence', regexp_replace('sentence', ',', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10904, 2)\n"
     ]
    }
   ],
   "source": [
    "print((sentenceData.count(), len(sentenceData.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Partition Training & Test sets\n",
    "(train_set, val_set) = sentenceData.randomSplit([0.8, 0.2], seed = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) \n",
    "nb = NaiveBayes(smoothing=1)\n",
    "pipeline = Pipeline(stages=[tokenizer,hashtf,idf,nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|            sentence|label|               words|                  tf|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    غبي     امس ا...|    0|[, , , , غبي, , ,...|(65536,[2049,2488...|(65536,[2049,2488...|[-347.75393870900...|[0.99504370273935...|       0.0|\n",
      "|    للاسف ـ بعض ـ...|    0|[, , , , للاسف, ـ...|(65536,[12736,146...|(65536,[12736,146...|[-167.69766584039...|[0.99999998732112...|       0.0|\n",
      "|   بعدين هالعالم ...|    0|[, , , بعدين, هال...|(65536,[1390,2168...|(65536,[1390,2168...|[-401.99481174627...|[0.80530086483193...|       0.0|\n",
      "|   تراي ألغيت حسا...|    0|[, , , تراي, ألغي...|(65536,[2356,6840...|(65536,[2356,6840...|[-490.46329807627...|[2.50975535212321...|       2.0|\n",
      "|   عزازي ومزعل فر...|    0|[, , , عزازي, ومز...|(65536,[6807,1563...|(65536,[6807,1563...|[-95.677690544437...|[0.00222484997903...|       2.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Data tranform using pipeline\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "train_df.show(5)\n",
    "predictions_tf = pipelineFit.transform(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score  = 81.31%\n"
     ]
    }
   ],
   "source": [
    "#F1 score\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_tf = evaluator.evaluate(predictions_tf)\n",
    "print(\"F1 score  = {0:.2%}\".format(f1_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 82.00%\n"
     ]
    }
   ],
   "source": [
    "#Precision\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision_tf = evaluator.evaluate(predictions_tf)\n",
    "print(\"Precision = {0:.2%}\".format(precision_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 81.44%\n"
     ]
    }
   ],
   "source": [
    "#Recall\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall_tf= evaluator.evaluate(predictions_tf)\n",
    "print(\"Recall = {0:.2%}\".format(recall_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "cv = CountVectorizer(vocabSize=2**16,inputCol=\"words\", outputCol='features')\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "pipeline = Pipeline(stages=[tokenizer,cv,nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|            sentence|label|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    غبي     امس ا...|    0|[, , , , غبي, , ,...|(33713,[1,6,31,37...|[-126.94576332948...|[0.95589386375133...|       0.0|\n",
      "|    للاسف ـ بعض ـ...|    0|[, , , , للاسف, ـ...|(33713,[1,5,26,92...|[-49.793908211457...|[0.94939841822302...|       0.0|\n",
      "|   بعدين هالعالم ...|    0|[, , , بعدين, هال...|(33713,[1,21,25,1...|[-149.78066391473...|[0.98148174156400...|       0.0|\n",
      "|   تراي ألغيت حسا...|    0|[, , , تراي, ألغي...|(33713,[1,10,15,1...|[-153.13229815384...|[0.36174043228756...|       2.0|\n",
      "|   عزازي ومزعل فر...|    0|[, , , عزازي, ومز...|(33713,[1,127,131...|[-60.668158619948...|[0.66093369190816...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Data tranform using pipeline\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "train_df.show(5)\n",
    "predictions_cv = pipelineFit.transform(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 84.75%\n"
     ]
    }
   ],
   "source": [
    "## Evaluation of Model\n",
    "# F1 score\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_cv = evaluator.evaluate(predictions_cv )\n",
    "print(\"F1 score = {0:.2%}\".format(f1_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 86.23%\n"
     ]
    }
   ],
   "source": [
    "# Precision\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision_cv = evaluator.evaluate(predictions_cv )\n",
    "print(\"Precision = {0:.2%}\".format(precision_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 84.93%\n"
     ]
    }
   ],
   "source": [
    "# Recall\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall_cv= evaluator.evaluate(predictions_cv )\n",
    "print(\"Recall = {0:.2%}\".format(recall_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "ngram = NGram(n=2, inputCol=\"words\", outputCol=\"ngrams\")\n",
    "cv = CountVectorizer(vocabSize=2**16,inputCol=\"ngrams\", outputCol='features')\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "pipeline = Pipeline(stages=[tokenizer,ngram, cv,nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data tranform using pipeline\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "\n",
    "predictions_ng = pipelineFit.transform(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>words</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>غبي     امس الشوط الاول كان مليون خطأ سواه...</td>\n",
       "      <td>0</td>\n",
       "      <td>[, , , , غبي, , , , , امس, الشوط, الاول, كان, ...</td>\n",
       "      <td>[ ,  ,  ,  غبي, غبي ,  ,  ,  ,  امس, امس الشوط...</td>\n",
       "      <td>(6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-138.67972596430948, -148.68885111115392, -14...</td>\n",
       "      <td>[0.9848509991684783, 4.430601701027925e-05, 0....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>للاسف ـ بعض ـ البشر</td>\n",
       "      <td>0</td>\n",
       "      <td>[, , , , للاسف, ـ, بعض, ـ, البشر]</td>\n",
       "      <td>[ ,  ,  ,  للاسف, للاسف ـ, ـ بعض, بعض ـ, ـ البشر]</td>\n",
       "      <td>(3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-47.27187546443951, -51.141152012413265, -49....</td>\n",
       "      <td>[0.8762638452251387, 0.018290662629250255, 0.1...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بعدين هالعالم كله خطا وحنا صح رايح تكتشفين ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[, , , بعدين, هالعالم, كله, خطا, وحنا, صح, راي...</td>\n",
       "      <td>[ ,  ,  بعدين, بعدين هالعالم, هالعالم كله, كله...</td>\n",
       "      <td>(2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-97.03067181241558, -103.98411083719797, -101...</td>\n",
       "      <td>[0.990280565232438, 0.0009460586418517492, 0.0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>تراي ألغيت حسابي   تجربة اسبوع كفاية تخليني...</td>\n",
       "      <td>0</td>\n",
       "      <td>[, , , تراي, ألغيت, حسابي, , , تجربة, اسبوع, ك...</td>\n",
       "      <td>[ ,  ,  تراي, تراي ألغيت, ألغيت حسابي, حسابي ,...</td>\n",
       "      <td>(3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-154.80930360421678, -165.56950339404435, -15...</td>\n",
       "      <td>[0.9929492762715695, 2.1078110197880356e-05, 0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>عزازي ومزعل فرحان افضل منه</td>\n",
       "      <td>0</td>\n",
       "      <td>[, , , عزازي, ومزعل, فرحان, افضل, منه]</td>\n",
       "      <td>[ ,  ,  عزازي, عزازي ومزعل, ومزعل فرحان, فرحان...</td>\n",
       "      <td>(2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-43.60853133280692, -46.626094110156544, -44....</td>\n",
       "      <td>[0.7359144954835317, 0.03600115999483327, 0.22...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  \\\n",
       "0      غبي     امس الشوط الاول كان مليون خطأ سواه...      0   \n",
       "1                                للاسف ـ بعض ـ البشر      0   \n",
       "2     بعدين هالعالم كله خطا وحنا صح رايح تكتشفين ...      0   \n",
       "3     تراي ألغيت حسابي   تجربة اسبوع كفاية تخليني...      0   \n",
       "4                         عزازي ومزعل فرحان افضل منه      0   \n",
       "\n",
       "                                               words  \\\n",
       "0  [, , , , غبي, , , , , امس, الشوط, الاول, كان, ...   \n",
       "1                  [, , , , للاسف, ـ, بعض, ـ, البشر]   \n",
       "2  [, , , بعدين, هالعالم, كله, خطا, وحنا, صح, راي...   \n",
       "3  [, , , تراي, ألغيت, حسابي, , , تجربة, اسبوع, ك...   \n",
       "4             [, , , عزازي, ومزعل, فرحان, افضل, منه]   \n",
       "\n",
       "                                              ngrams  \\\n",
       "0  [ ,  ,  ,  غبي, غبي ,  ,  ,  ,  امس, امس الشوط...   \n",
       "1  [ ,  ,  ,  للاسف, للاسف ـ, ـ بعض, بعض ـ, ـ البشر]   \n",
       "2  [ ,  ,  بعدين, بعدين هالعالم, هالعالم كله, كله...   \n",
       "3  [ ,  ,  تراي, تراي ألغيت, ألغيت حسابي, حسابي ,...   \n",
       "4  [ ,  ,  عزازي, عزازي ومزعل, ومزعل فرحان, فرحان...   \n",
       "\n",
       "                                            features  \\\n",
       "0  (6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  (3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                       rawPrediction  \\\n",
       "0  [-138.67972596430948, -148.68885111115392, -14...   \n",
       "1  [-47.27187546443951, -51.141152012413265, -49....   \n",
       "2  [-97.03067181241558, -103.98411083719797, -101...   \n",
       "3  [-154.80930360421678, -165.56950339404435, -15...   \n",
       "4  [-43.60853133280692, -46.626094110156544, -44....   \n",
       "\n",
       "                                         probability  prediction  \n",
       "0  [0.9848509991684783, 4.430601701027925e-05, 0....         0.0  \n",
       "1  [0.8762638452251387, 0.018290662629250255, 0.1...         0.0  \n",
       "2  [0.990280565232438, 0.0009460586418517492, 0.0...         0.0  \n",
       "3  [0.9929492762715695, 2.1078110197880356e-05, 0...         0.0  \n",
       "4  [0.7359144954835317, 0.03600115999483327, 0.22...         0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score  = 71.15%\n"
     ]
    }
   ],
   "source": [
    "## Evaluation of the model\n",
    "#F1 score\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_ng = evaluator.evaluate(predictions_ng)\n",
    "print(\"F1 score  = {0:.2%}\".format(f1_ng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision  = 77.10%\n"
     ]
    }
   ],
   "source": [
    "#Precision\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision_ng = evaluator.evaluate(predictions_ng)\n",
    "print(\"Precision  = {0:.2%}\".format(precision_ng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall  = 71.94%\n"
     ]
    }
   ],
   "source": [
    "#Recall\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall_ng= evaluator.evaluate(predictions_ng)\n",
    "print(\"Recall  = {0:.2%}\".format(recall_ng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TF</th>\n",
       "      <td>81.306%</td>\n",
       "      <td>82.002%</td>\n",
       "      <td>81.436%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag of words</th>\n",
       "      <td>84.754%</td>\n",
       "      <td>86.233%</td>\n",
       "      <td>84.932%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-grams</th>\n",
       "      <td>71.15%</td>\n",
       "      <td>77.103%</td>\n",
       "      <td>71.941%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             F1 score Precision   Recall\n",
       "TF            81.306%   82.002%  81.436%\n",
       "bag of words  84.754%   86.233%  84.932%\n",
       "N-grams        71.15%   77.103%  71.941%"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "l_tf=[f1_tf,precision_tf,recall_tf]\n",
    "l_cv=[f1_cv,precision_cv,recall_cv]\n",
    "l_ng=[f1_ng,precision_ng,recall_ng]\n",
    "\n",
    "l_tf_set=[str(np.round(item*100,3))+'%' for item in l_tf]\n",
    "l_cv_set=[str(np.round(item*100,3))+'%' for item in l_cv]\n",
    "l_ng_set=[str(np.round(item*100,3))+'%' for item in l_ng]\n",
    "index=['F1 score','Precision','Recall']\n",
    "metrics=pd.DataFrame(l_tf_set,index=index,columns=['TF'])\n",
    "metrics['bag of words']=l_cv_set\n",
    "metrics['N-grams']=l_ng_set\n",
    "metrics.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
