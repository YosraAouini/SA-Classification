{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import string\n",
    "import regex as re\n",
    "from pyarabic import araby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>prediction_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>تصويري عبدالرحمن الدغيلبي عيش السعودية قطفنا ا...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>تصويري عبدالرحمن الدغيلبي عيش السعودية قطفنا ا...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>تصويري متنوع الارشيف عيش السعودية عبدالرحمن ال...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>عيش السعودية وطني قلبي ينبع أملج السعودية</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>بوابة الوفد الدنيا لتنشيط السياحة الداخلية</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  prediction_sentiment\n",
       "0  تصويري عبدالرحمن الدغيلبي عيش السعودية قطفنا ا...                   1.0\n",
       "1  تصويري عبدالرحمن الدغيلبي عيش السعودية قطفنا ا...                   1.0\n",
       "2  تصويري متنوع الارشيف عيش السعودية عبدالرحمن ال...                   1.0\n",
       "3          عيش السعودية وطني قلبي ينبع أملج السعودية                   1.0\n",
       "4         بوابة الوفد الدنيا لتنشيط السياحة الداخلية                   1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Import tweets with sentiment analysis \n",
    "data=pd.read_csv('Results/predictions_tweet.csv',header=0, delimiter=\";\",  encoding=\"utf-8-sig\") \n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209657"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tweet.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction_sentiment\n",
       "0.0     22407\n",
       "1.0    140569\n",
       "2.0     46681\n",
       "Name: tweet, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('prediction_sentiment').count().tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الرياض</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>المجمعة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>المجمعه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>القويعية</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>القويعيه</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        place\n",
       "0     الرياض \n",
       "1    المجمعة \n",
       "2    المجمعه \n",
       "3   القويعية \n",
       "4   القويعيه "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Import keywords used to search location within the tweet text\n",
    "pd_places =pd.read_csv('Data/listeplaces2.csv',header=0, delimiter=\";\",  encoding=\"utf-8-sig\") \n",
    "pd_places.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "places= pd_places['place'].tolist() \n",
    "### Eliminate espaces in places list\n",
    "list_place=[]\n",
    "for i in range(len(places)):\n",
    "\tx=places[i].strip()\n",
    "\tlist_place.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>normalized_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ابها</td>\n",
       "      <td>أبها</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الطايف</td>\n",
       "      <td>الطائف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>جده</td>\n",
       "      <td>جدة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بريده</td>\n",
       "      <td>بريدة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>املج</td>\n",
       "      <td>أملج</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    place normalized_place\n",
       "0    ابها             أبها\n",
       "1  الطايف           الطائف\n",
       "2     جده              جدة\n",
       "3   بريده            بريدة\n",
       "4    املج             أملج"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Normalized_places is a list that will be used on normalization of location name\n",
    "normalized_places=pd.read_csv('Data/normalized_places.csv',header=0, delimiter=\";\",  encoding=\"utf-8-sig\") \n",
    "normalized_places.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_place1=[]\n",
    "list_place2=[]\n",
    "for i in range(normalized_places.shape[0]):\n",
    "\tx1=normalized_places.place[i].strip()\n",
    "\tx2=normalized_places.normalized_place[i].strip()\n",
    "\tlist_place1.append(x1)\n",
    "\tlist_place2.append(x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_places['place']=list_place1\n",
    "normalized_places['normalized_place']=list_place2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_places=normalized_places.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def location(text):\n",
    "\tlocation_i= \" \" \n",
    "\tlist_w=str(text).split()\n",
    "\tfor i in range(len(list_w)) :\n",
    "\t\tif list_w[i]=='وادي' and i<len(list_w)-1 and len(list_w[i+1])!=0   :\n",
    "\t\t\tlocation_i +='وادي ' + list_w[i+1]\n",
    "\t\t\tlocation_i += \" \"\n",
    "\t\telif list_w[i]=='وادي'  and i<len(list_w)-2  and len(list_w[i+2])!=0 and (list_w[i+1]=='بني' or list_w[i+1]=='بن' ) :\n",
    "\t\t\tlocation_i +='وادي ' + list_w[i+1] + list_w[i+2]\n",
    "\t\t\tlocation_i += \" \"\n",
    "\t\telif list_w[i]=='قرية' and i<len(list_w)-1   and len(list_w[i+1])!=0 :\n",
    "\t\t\tlocation_i +='قرية ' + list_w[i+1]\n",
    "\t\t\tlocation_i += \" \"\n",
    "\t\telif list_w[i]=='جزر' and i<len(list_w)-1 and len(list_w[i+1])!=0   :\n",
    "\t\t\tlocation_i +='جزر ' + list_w[i+1]\n",
    "\t\t\tlocation_i += \" \"\n",
    "\t\telif list_w[i]=='بدر' and i<len(list_w)-1 and list_w[i+1]=='الجنوب':\n",
    "\t\t\tlocation_i +='  بدر الجنوب ' \n",
    "\t\telif list_w[i]=='عيون' and i<len(list_w)-1 and list_w[i+1]=='الجواء':\n",
    "\t\t\tlocation_i +=' عيون الجواء '\n",
    "\t\telif list_w[i]=='رياض'and i<len(list_w)-1 and list_w[i+1]=='الخبراء':\n",
    "\t\t\tlocation_i +=' رياض الخبراء   '\n",
    "\t\telif list_w[i]=='مهد' and i<len(list_w)-1 and list_w[i+1]=='الذهب':\n",
    "\t\t\tlocation_i +=' مهد الذهب '\n",
    "\t\telif list_w[i]=='بني' and i<len(list_w)-1 and list_w[i+1]=='تميم':\n",
    "\t\t\tlocation_i +='  بني تميم '\n",
    "\t\telif list_w[i]=='بني' and i<len(list_w)-1 and list_w[i+1]=='حسن':\n",
    "\t\t\tlocation_i +='  بني حسن '\n",
    "\t\telif list_w[i]=='الحدود' and i<len(list_w)-1 and (list_w[i+1]=='الشماليه' or list_w[i+1]=='الشمالية'):\n",
    "\t\t\tlocation_i +=' الحدود الشمالية   '\n",
    "\t\telse:\n",
    "\t\t\tfor place in list_place: \n",
    "\t\t\t\tif list_w[i]==place:\n",
    "\t\t\t\t\tlocation_i += place\n",
    "\t\t\t\t\tlocation_i += \" \"\n",
    "\tx=list(dict.fromkeys(location_i.split()))\n",
    "\tlocation=' '.join([str(elem) for elem in x])\n",
    "\treturn location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_eliminated=['بني','الشمالية','وادي','قرية']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'وادي حنيفه'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet=\"عيش السعوديه وادي حنيفه\"\n",
    "location(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the location is: \n"
     ]
    }
   ],
   "source": [
    "tweet=\"تعتبر السياحة السعودية القطاعات الناشئة تعد السياحة الدينية أهم ركائزها كونها مهد الدين الإسلامي يجعلها محل جذب سياحي\"\n",
    "print('the location is:',location(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_location(text):\n",
    "\tlocation_i= \" \"\n",
    "\tlist_w=str(text).split() # to split text into words\n",
    "\tfor i in range(len(list_w)): # for each word in the text \n",
    "\t\tx_i=\"\"\t\n",
    "\t\tfor j in range(normalized_places.shape[0]):\n",
    "\t\t\tif list_w[i].strip()==normalized_places.place[j].strip(): # if the word is equal to a place noun \n",
    "                                                                      #  from the normalized list\n",
    "\t\t\t\tx_i +=normalized_places.normalized_place[j] # the normalized from of this noum is returned to the x_i list\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tx_i +=\"\"\n",
    "\t\tif len(x_i)==0:  # if the length(x_i) is 0 ( x_i don't contain any place) the initial noun of the place is returned \n",
    "\t\t\tlocation_i += list_w[i]\n",
    "\t\t\tlocation_i += \" \"\n",
    "\t\telse: \n",
    "\t\t\tlocation_i += x_i # else the location will be equal the normalized form\n",
    "\t\t\tlocation_i += \" \"\n",
    "\n",
    "\tx=list(dict.fromkeys(location_i.split())) # eliminate the duplicate places noun , a list is created\n",
    "\tlocation=' '.join([str(elem) for elem in x]) # join  the created list below into a string\n",
    "\tif location.strip() in list_eliminated: # if the location contain only one the word in the list_eliminated \n",
    "                                            # list_eliminated=['بني','الشمالية','وادي','قرية']\n",
    "                                            # the location will be set as empty \n",
    "\t\tlocation='' \n",
    "\telse: \n",
    "\t\tlocation\n",
    "\treturn location\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply the location function \n",
    "location_list=data['tweet'].apply(lambda x: location(x))\n",
    "data['location_0']=location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply the normalize_location function \n",
    "location_normalized_list=data['location_0'].apply(lambda x: normalize_location(x))\n",
    "data['location']=location_normalized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top n visted places (n=50)\n",
    "n=50\n",
    "\n",
    "most_visited_places_list=data.groupby('location').count().tweet.nlargest(n).index.values\n",
    "most_visited_places=most_visited_places_list[1:n-1]\n",
    "column_names = [\"location\", \"Negative\", \"Neutral\",\"Positive\" ]\n",
    "data_result= pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(most_visited_places)-1):\n",
    "\txi=data[data['location']==most_visited_places[i]]\n",
    "\tdata_result.loc[i,'location']=most_visited_places[i]\n",
    "\tdata_result.loc[i,'Negative']=len(xi[xi['prediction_sentiment']==0.0])\n",
    "\tdata_result.loc[i,'Neutral']=len(xi[xi['prediction_sentiment']==1.0])\n",
    "\tdata_result.loc[i,'Positive']=len(xi[xi['prediction_sentiment']==2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_visted_places=data.groupby('location').count().tweet.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "          136977\n",
       "الرياض      5640\n",
       "العلا       4269\n",
       "حائل        3514\n",
       "الطائف      3389\n",
       "Name: tweet, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_visted_places.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_visted_places.to_csv(r'Output/list_of_visted_places.csv', index = True, header=True, sep=\";\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'Output/data_tweets_with_location.csv', index = False, header=True, sep=\";\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_result.to_csv(r'Results/most_visited_places.csv', index = False, header=True, sep=\";\", encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
